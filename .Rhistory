setwd("C:/Users/sneha/Dropbox/post doc/kendall")
setwd("C:/Users/sneha/Dropbox/post doc/kendall")
library(MASS)
library(far)
library("refund")
library("gee")
library("cvTools")
library("Matrix")
source("supplementary_functions.R")
setwd("C:/Users/sneha/Dropbox/post doc/kendall/src")
library(MASS)
library(far)
library("refund")
library("gee")
library("cvTools")
library("Matrix")
source("supplementary_functions.R")
func=as.matrix(read.csv("DTI_x.csv",header = F))
scalar=as.matrix(read.csv("DTI_y.csv",header = F))
pos=as.matrix(read.csv("DTI_pos.csv",header = F))
library(MASS)
library(far)
library("refund")
library("gee")
library("cvTools")
library("Matrix")
source("supplementary_functions.R")
func=as.matrix(read.csv("DTI_x.csv",header = F))
scalar=as.matrix(read.csv("DTI_y.csv",header = F))
pos=as.matrix(read.csv("DTI_pos.csv",header = F))
int=pos[2,1]-pos[1,1]
n=nrow(func)
setwd("C:/Users/sneha/Dropbox/post doc/kendall")
library(MASS)
library(far)
library("refund")
library("gee")
library("cvTools")
library("Matrix")
source("supplementary_functions.R")
func=as.matrix(read.csv("DTI_x.csv",header = F))
scalar=as.matrix(read.csv("DTI_y.csv",header = F))
pos=as.matrix(read.csv("DTI_pos.csv",header = F))
int=pos[2,1]-pos[1,1]
n=nrow(func)
##output the p-value for##
FU=FU(func,scalar,n,int)
FU
library(MASS)
library(fda)
library(svd)
library(gskat)
library(far)
library(cvTools)
library(fdapace)
source("supplementary_functions.R")
dat=read.csv("live_bids_open.csv")
ID=unique(dat$ID)
n=length(unique(ID))
Lt=Lx=list()
max(dat$Time)
Y=NULL
for(i in 1: n)
{
tmp=which(dat$ID==ID[i])
Lt[[i]]=dat$Time[tmp]
Lx[[i]]=(dat$Bids[tmp])
Y[i]=(dat$Opening[tmp[1]])
}
res= FPCA(Lx, Lt,list(dataType='Sparse',  verbose=TRUE))
pos=res$workGrid
phi=res$phi
mu=res$mu
fpc=res$xiEst
xtilde=matrix(0,nrow=n,ncol=length(pos))
for( i in 1:n)
{
xtilde[i,]=mu+apply(phi,1,function(v) crossprod(v,fpc[i,]))
}
x=xtilde
y=Y
int=pos[2]-pos[1]
#FU_perm=FU_perm(x,y,n,1000)
fu_p=FU(x,y,n,int)
###This is the p-value###
fu_p
setwd("C:/Users/sneha/Dropbox/post doc/kendall/Function association project")
###This demonsrate the method for dense functional data based
### on test statistics in eq (2) and (3) of the manuscript. Preprocessed Diffusion Tensor Imaging
### dataset is provided.
library(MASS)
library(far)
library("refund")
library("gee")
library("cvTools")
library("Matrix")
source("supplementary_functions.R")
func=as.matrix(read.csv("DTI_x.csv",header = F))
scalar=as.matrix(read.csv("DTI_y.csv",header = F))
pos=as.matrix(read.csv("DTI_pos.csv",header = F))
int=pos[2,1]-pos[1,1]
n=nrow(func)
##output the p-value for##
FU=FU(func,scalar,n,int)
FU
###This demonsrate the method for sparse functional data based
### on test statistics in eq (4) of the manuscript. It is applied on the
### ebay dataset.
library(MASS)
library(fda)
library(svd)
library(gskat)
library(far)
library(cvTools)
library(fdapace)
source("supplementary_functions.R")
#### preparing the data for the FPCA function available in fdapace package###
dat=read.csv("live_bids_open.csv")
ID=unique(dat$ID)
n=length(unique(ID))
Lt=Lx=list()
max(dat$Time)
Y=NULL
for(i in 1: n)
{
tmp=which(dat$ID==ID[i])
Lt[[i]]=dat$Time[tmp]
Lx[[i]]=(dat$Bids[tmp])
Y[i]=(dat$Opening[tmp[1]])
}
#### using FPCA to obtain funcitions from the predicted scores  (see page 6) of the manuscript)
res= FPCA(Lx, Lt,list(dataType='Sparse',  verbose=TRUE))
pos=res$workGrid
phi=res$phi
mu=res$mu
fpc=res$xiEst
xtilde=matrix(0,nrow=n,ncol=length(pos))
for( i in 1:n)
{
xtilde[i,]=mu+apply(phi,1,function(v) crossprod(v,fpc[i,]))
}
#### implementing the proposed test using test statistic (4) #####
x=xtilde
y=Y
int=pos[2]-pos[1]
fu_p=FU(x,y,n,int)
###This is the p-value###
fu_p
